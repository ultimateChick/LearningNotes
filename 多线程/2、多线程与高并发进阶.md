# 多线程与高并发进阶

## CAS：Compare and Swap

![image-20200723133651131](C:\Users\q1367\Desktop\jdk\CAS图解.png)

写值经过多次确认，在没有加锁的情况下，保证线程一致性地去改动值

### ABA问题

中间经过其他线程的改动，又回到原值，中间可能发生了其他改动，需要能够感知到

解决方案：给数值加上版本号，每次改动了就给数值改动版本号

**AtomicStampedReference**

### 原子类的支持：Unsafe类

- 直接操作内存
  - allocateMemory putXX freeMemory……
- 直接生成类实例
- 直接操作类或者实例变量
- CAS相关操作

可以说等同于c c++的指针，内部API已经关闭了，不可能用户调用

c -> malloc free

c++ -> new delete



### 底层汇编：深入CAS native源码（native是JVM负责的

CAS在底层内联方法实现上有一条汇编语言 ASM

LOCK_IF_MP：mp-》multiProcessors

cmpxchg，硬件级别直接支持

最终实现 **lock cmpxchg** 指令，cmpxchg本质上非原子性，lock可以保证其原子性

lock表示当前cpu在执行此处汇编指令的时候不允许其他cpu打断

### 硬件级别实现

硬件：lock指令在执行后面指令的时候锁定一个北桥信号（不采用锁总线的方式）

**CAS和Synchronized和Volatile底层实现是一样的，都和lock有关系**

### 工具：JOL=Java Object Layout

可以查看对象在内存中的内存布局，new出来的对象的具体布局是什么样的？

**引申问题：Object o = new Object()在内存中占了多少字节**

![image-20200723142716563](C:\Users\q1367\Desktop\jdk\图示空白Object对象的布局和大小.png)

这个布局和synchronized的实现息息相关

![image-20200723141127585](C:\Users\q1367\Desktop\jdk\对象在内存中的存储布局.png)

- markword：关于锁的信息，synchronized所有信息都在这里

- 类型指针class pointer：这个对象所属于的运行时类，指针指向XXX.class

  **markword和类型指针加起来叫做对象头**

- 实例数据instance data：实例数据都在这里(int m = 8;)

- 对齐：当我们整个对象的字节数不能被8整除时，把长度向上补齐到8的倍数

  - 原因：jvm在读内存中值的时候，按照总线的宽度来读，按照8的倍数来读，效率特别高

#### 引申：类型指针、普通对象指针的大小

观察java的启动参数可以知道，除了默认初始化堆大小和最大堆大小之外，java还默认开启

-XX:+UseCompressedClassPointers   -XX:+UseCompressedOops

我们的jvm虚拟机是64位的，name默认的类型指针也应该是64位的，即八个字节

压缩过后我们得到的是四个字节的类型指针，所以对象头中的classpointer也应该是四个字节的

**普通对象指针：**

例子：String s = new String();

从栈中的引用变量s出发到堆中具体的String对象的指针，就是普通对象指针

压缩后，默认也是四个字节的

#### markword：8个字节；class pointer：4个字节；对象头12个字节

![图示空白Object对象的布局和大小](C:\Users\q1367\Desktop\jdk\图示空白Object对象的布局和大小.png)

前八个字节是markword，后面四个是class pointer

没有实例变量，这块为空

最后四个是对齐的padding部分

回答问题：Object o = new Object()在内存中占了多少字节

开启了压缩，markword是八个字节，class pointer是四个字节，padding是四个字节，o本身oops四个字节，加起来20个字节；

不开启压缩，markword八个字节，class pointer八个字节，为八的倍数不进行对齐，o本身oops八个字节，加起来24个字节。

##### 进阶

public class User{ int i =0; String s = new String();}

User u = new User();内存布局

```
markword 8个字节
class pointer 开启压缩四个字节   
-----对象头结束---
int i； 四个字节
String s；开启压缩，oops四个字节
-----实例变量结束------
padding对齐，四个字节
-----对齐结束------
总共24个字节
```

## markword 解析

引入

```
Object o = new Object();
synchronized(o){
	sout(ClassLayout.parseInstance(o).toPrintable());
}
```

锁的信息记录在o对象里

代码本身是不被锁定的

**上锁之前**

![图示空白Object对象的布局和大小](C:\Users\q1367\Desktop\jdk\图示空白Object对象的布局和大小.png)

**上锁之后**

![image-20200723144731484](C:\Users\q1367\Desktop\jdk\上锁之后的对象内存布局.png)

### 锁的升级

刚刚new出对象--偏向锁--轻量级锁（自旋锁(无锁：CAS等待)、自适应自旋）--重量级锁

synchronized优化过程和markdown息息相关

![image-20200723150845702](C:\Users\q1367\Desktop\jdk\锁信息.png)

##### 分代年龄

JVM->GC

****

我们JVM的内存堆分成young和old两个区域

默认young:old = 1: 2

young还可以划分成 eden区和survive区，survive区又可以划分成from和to区

他们的大小比例是eden:from:to = 8:1:1

jvm每次为新生代服务时，都会使用eden和survive区中的某一块，即新生代实际可用的内存空间是young区的90%

这样的年龄划分是为了更好地为java对象服务，管理好堆内存中的对象，包括内存的分配和回收

****

一个对象被垃圾回收器尝试回收一次，分代年龄就会+1，年龄达到一定程度，（JVM方式默认是15岁，CMS方式默认是6岁）会变成老年代中的对象

****

分代年龄是4个bit，表示它最多是15岁

**TIP：锁升级的时候会把Markword备份到线程栈，线程栈当中会有hashCode、分代年龄等**

### 无锁态（new）-》hashcode

这里存储的是identityHashCode，要我们对对象的hashCode方法进行调用之后才会存进来

### 偏向锁

通过给对象markword标记当前线程指针javaThread，来指示此锁为某个特定线程持有

在争用不激烈的情况下，由于多次进入同步代码块的线程往往是第一次申请进入的线程，采用此种方式可以省略向系统申请重量级锁的性能开销，提高效率。

### 轻量级锁

当有另外一个线程，只要发生另外一次竞争，就自动升级为轻量级锁

升级步骤：

- 撤销偏向锁状态
- 每个线程栈里面各自生成一个对象，LockRecord（锁记录
  - 这个锁记录当中其实有我们对象的hashCode的值
- 两个线程发生竞争，看哪个线程能把自己的LR记录到竞争对象的markword当中
- 这个竞争的过程采用的是CAS自旋方式

##### 自旋的终止

我们无法一直保持竞争过程中自旋操作的持续进行，这会带来得不偿失的性能消耗

因此在自旋程度达到一定量级时，我们会进一步对锁进行升级

**升级条件：**某个线程在竞争的过程中发生了超过10次的自选操作，或者是在自旋等待的线程超过整个cpu核心数的一半，整个锁申请为重量级锁，jdk1.6之后加入了自适应自旋锁

#### 自适应自旋锁 Adaptive Self Spining

自适应自旋锁使得我们可以免于自旋锁到重量级锁的调优（修改升级条件等），jvm会根据当前的性能状态决定是否升级

### 重量级锁

概念引入：

**用户态：**轻量级锁是一种用户态的循环操作，但是这个循环是需要消耗资源的，如果线程竞争特别激烈，许多个循环操作就会大大占用我们的系统资源

**内核态：**一般来说用户态进入内核态取用系统资源是比较消耗资源的，但是在用户态消耗特别大的时候，内核态的消耗就显得性价比很高了

现代操作系统把程序的执行状态分成用户态和内核态两种，用户态的程序不能直接和硬件交互（和CPU级别有关系，用户态Ring3，内核态Ring0

我们拿重量级锁（mutex）的时候，需要经由内核态和操作系统取用此资源，有数量限制

申请到了，markword就会记录指向mutex的指针

#### 升级到重量级锁的变化

- 每个重量级锁下面都有一个队列
- 队列中存放的是想要使用此锁的线程引用，没有轮到执行的线程是不消耗任何cpu的，处于wait状态
- 操作系统可以唤醒队列中的wait线程进行工作
- 这个队列不是有序的，synchronized是一把非公平锁

### 锁消除 lock eliminate

```java
public void add(String str1, String str2){
	StringBuffer sb = new StringBuffer();
	sb.append(str1).append(str2);
}
```

我们知道StringBuffer是线程安全的，内部有很多synchronized修饰过的关键方法，但是这个情况下，sb这个引用只会在add方法中使用，不可能被其他线程引用（局部变量，方法栈为某个线程私有），因此sb是不可能共享的资源，JVM会自动消除sb内部的锁

### 锁粗化 lock coarsening

```java
public String test(String str){
	int i = 0;
    StringBuffer sb = new StringBuffer();
    while(i < 100){
        sb.append(str);
        i++;
    }
    return sb.toString();
}
```

循环内加锁的情况可能会被jvm优化成一个锁内进行循环

除非是循环特别消耗时间，jvm需要给其他线程执行的机会，才会摒弃这种粗化

## Synchronized汇编级底层实现

### 概念引入：JIT-Just In Time Compiler

即时编译器

平时java的执行是解释执行的，把字节码文件中的指令逐条交给JVM进行解释运行，这样子的效率不高

HotSpot（oracle的）等JVM实现中有一个热点代码机制，可以标识出执行期间多次执行的代码

JVM会对他们进行即时编译，直接编译成机器语言，不再重新解释了

#### 辅助插件：hsdis热点反汇编

java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly T

会看到底层进行了

C1 Compile Level 1

C2 Compile Level 2

二级优化，找到m()/n()的汇编码，会看到lock comxchg指令

### Synchronized五层实现

1. java代码层级：使用synchronized关键字
2. 字节码层级：monitorenter、monitorexit（监视你这把锁
3. JVM执行过程中自动升级：无锁态--偏向锁--轻量级锁（自旋锁、自适应自旋锁）--重量级锁
4. 汇编层级：lock comxchg

## Volatile（可变的、易变的

### HelloVolatile！

![image-20200723183024756](C:\Users\q1367\Desktop\jdk\引入小程序.png)

运行起来，我们会发现t.running的设置并不能阻止死循环方法的运行

如果我们打开running的volatile声明

程序就会按照我们的设想运行

这里体现的就是 **线程可见性！**



### 堆中数据到线程副本

![image-20200727145750500](C:\Users\q1367\Desktop\JVM\纤程副本.png)

当线程要使用到对象中某个数值时，会从堆中复制一份到线程栈帧中，通常情况下，这个数值在自己线程内的改动并不会即时的反应到其他线程中，这就叫线程之间的不可见。

### volatile修饰引用类型变量会发生什么（存疑）

从实际的运行效果上看，虽然我们没有直接用volatile关键字修饰对象中的类变量init_value，而是修改了对象的引用，但是我们看到对象中的普通实例变量仍然实行了线程间的可见性，也就是说间接也相当于被volatile关键字修饰了。所以，在这里问题也就基本上有了答案，那就是：**“被volatile关键字修饰的对象作为类变量或实例变量时，其对象中携带的类变量和实例变量也相当于被volatile关键字修饰了”。**

**从volatile的语义上来说，只有对象的地址值发生了变化，才会让其他县城可见**

### 线程可见性

如果我们给running属性添加了volatile声明

那么我们在一个线程（这里是主线程）中对running进行了更改

那么这个线程就会通知到其他使用到这个变量的线程

其他使用到这个变量的线程在下次使用这个变量的时候会根据我们的赋值，重新读取running的值，因此方法得到了终止



#### 线程可见性实现的硬件底层支持

MESI缓存一致性协议（归根结底是硬件来实现



#### MESI和线程可见性的关系！！！

首先，volatile是java语言层面给出的保证，MSEI协议是多核cpu保证cache一致性（后面会细说这个一致性）的一种方法，中间隔的还很远，我们可以先来做几个假设：

1. 回到远古时候，那个时候cpu只有单核，或者是多核但是保证sequence consistency[1]，当然也无所谓有没有MESI协议了。那这个时候，我们需要java语言层面的volatile的支持吗？当然是需要的，因为在语言层面编译器和虚拟机为了做性能优化，可能会存在指令重排的可能，而volatile给我们提供了一种能力，我们可以告诉编译器，什么可以重排，什么不可以。
2. 那好，假设更进一步，假设java语言层面不会对指令做任何的优化重排，那在多核cpu的场景下，我们还需要volatile关键字吗？答案仍然是需要的。因为 MESI只是保证了多核cpu的独占cache之间的一致性，但是cpu的并不是直接把数据写入L1 cache的，中间还可能有store buffer。有些arm和power架构的cpu还可能有load buffer或者invalid queue等等。因此，有MESI协议远远不够。
3. 再接着，让我们再做一个更大胆的假设。假设cpu中这类store buffer/invalid queue等等都不存在了，cpu是数据是直接写入cache的，读取也是直接从cache读的，那还需要volatile关键字吗？你猜的没错，还需要的。原因就在这个“一致性”上。consistency和coherence都可以被翻译为一致性，但是MSEI协议这里保证的仅仅coherence而不是consistency。那consistency和cohence有什么区别呢？下面取自wiki[2]的一段话：

> Coherence deals with maintaining a global order in which writes to a single location or single variable are seen by all processors. Consistency deals with the ordering of operations to multiple locations with respect to all processors.

因此，MESI协议最多只是保证了对于一个变量，在多个核上的读写顺序，对于多个变量而言是没有任何保证的。很遗憾，还是需要volatile～～

4. 好的，到了现在这步，我们再来做最后一个假设，假设cpu写cache都是按照指令顺序fifo写的，那现在可以抛弃volatile了吧？你觉得呢？我都写到标题4了，那肯定不行啊！因为对于arm和power这个weak consistency[3]的架构的cpu来说，它们只会保证指令之间有比如控制依赖，数据依赖，地址依赖等等依赖关系的指令间提交的先后顺序，而对于完全没有依赖关系的指令，比如x=1;y=2，它们是不会保证执行提交的顺序的，除非你使用了volatile，java把volatile编译成arm和power能够识别的barrier指令，这个时候才是按顺序的。

最后总结上文，答案就是：还需要～～

(写的比较随意，后续有空再补充详细，先凑活着看吧～～)

[1] [https://en.wikipedia.org/wiki/Sequential_consistency](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Sequential_consistency)

[2] [https://en.wikipedia.org/wiki/Consistency_model](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Consistency_model)

[3] Maranget, Luc, Susmit Sarkar, and Peter Sewell. "A tutorial introduction to the ARM and POWER relaxed memory models." Draft available from [http://www](https://link.zhihu.com/?target=http%3A//www/). cl. cam. ac. uk/~ pes20/ppc-supplemental/test7. pdf (2012).



作者：罗一鑫
链接：https://www.zhihu.com/question/296949412/answer/747494794
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



### 底层原理——计算机组成

![image-20200723183820455](C:\Users\q1367\Desktop\jdk\计算机组成.png)

#### 场景理解：假设我们从硬盘启动qq.exe

1. 计算机从磁盘通过总线把程序读入内存，这时候内存存储的是一条条的指令集合，还有相应的属性值，它占用的空间，存储的逻辑和其他支持加起来就称为进程
2. cpu中的PC(Programmer Counter)程序计数器，里面记录着指向当前程序要执行的下一条指令的地址，计算机通过PC的地址把下一条指令读入cpu，PC更新为新的下一条指令的地址
3. registers寄存器中就存放着当前指令要利用到的数据集，用来临时存放数据
4. CPU通过ALU(Arithmetic Logical Unit)逻辑运算单元，根据指令运行，从寄存器中取用数据，并往寄存器写入过程计算结果
5. 运算完毕，寄存器把计算结果写回内存

#### Cache相关

##### 存储器的层次结构

![image-20200723185547001](C:\Users\q1367\Desktop\jdk\存储器的层次结构.png)

##### 各层存储器的运行速度对比

![image-20200723185845800](C:\Users\q1367\Desktop\jdk\各层存储器的运行速度.png)

##### 多核CPU

![image-20200723190040219](C:\Users\q1367\Desktop\jdk\多核CPU.png)

L3是多核CPU所有核心共享的

##### 超线程

所谓的八核十六线程

**本质其实是一个ALU对应多个PC|Registers**

****

一个线程在CPU中运行，PC记录它运行到什么位置，Registers记录着这个线程的数据，ALU来进行线程的运算

一般的，在一个时刻只能执行一个线程

假如我们想要执行其他线程，那么就要把当前线程的状态（PC、registers中的内容）保存起来，并清空当前pc和registers的内容，加载另一个线程的状态，进行执行

这就是所谓的contextSwitch上下文切换

线程是操作系统执行的基本单位，进程是操作系统分配资源的基本单位

****

**假如：我们每个核心有两组Registers和PC，每组程序计数器和寄存器都各自加载一个线程的状态**

我们ALU只需要在不同组进行切换就可以执行上下文切换，而无需重新装载

这就是超线程

##### Cache Line的概念 缓存行对齐 伪共享

![image-20200723191813631](C:\Users\q1367\Desktop\jdk\缓存行对齐.png)

**常识：**

- CPU想要取用寄存器中缺失的数据，会逐层L1、L2、L3、主存读取目标数据
- 当我们从某层中找到目标数据的时候，也是逐层读回到CPU当中，

- 内存是按块从磁盘中读入数据，出于程序的局部性原理，我们的缓存读取也是按块来获取的，这样可以大大提高我们缓存的命中率

**缓存行（Cache Line）一行为八字节**

利用缓存行机制实现优化的实例原理：CPU级别的一致性是缓存行级别的一致性

优化方法：缓存行对齐

![image-20200723194532336](C:\Users\q1367\Desktop\jdk\disrupter.png)

这样的缓存行对齐可以保证无论缓存怎么装填属性，一个缓存行上都只有一个游标！在保持数据一致性（volatile）的时候不会线程之间相互干扰。

##### MESI Cache一致性协议：多个CPU核心之间的缓存一致性协议

Cache Line四种状态：

- Modified：被修改了
- Exclusive：独占
- Shared：共享读
- Invalid：无效（比如一个核心内对某个缓存行数据进行了修改，那么其他核心内的对应缓存行就会被设置为invalid）

这是X86的规范，缓存一致性协议有许多

jdk的Concurrent包中就有许多缓存行对齐的利用

##### 场景：如果有数据非常大，超过了缓存行的限制，怎么办？

**锁总线，这也是解决缓存一致性的万能方法**

我这个线程在从内存中取用这块数据时，其他线程、核心都必须等着；会影响效率

#### volatile特性之二：禁止指令重排序

##### CPU乱序执行

**原理：为了提高CPU的执行效率，对于能确保结果一致性的前提下，CPU可能打乱指令的执行顺序**

##### 确保指令有序性的机制，添加volatile声明的变化

volatile i;

字节码层级：属性多了一个ACC_VOLATILE的标记，交给虚拟机处理

JVM的内存屏障

一句话：JVM会在指令间设置屏障，屏障两边的指令不能重排，以保证有序性

![image-20200723235354701](C:\Users\q1367\Desktop\jdk\JSR内存屏障.png)

volatile在JVM层面的实现细节

![image-20200723235957167](C:\Users\q1367\Desktop\jdk\volatile实现细节.png)

这里的写操作，前面的SSB保证volatile修饰的对象的写入不会提前执行，而SLB可以保证写入完毕后才能被读取！

这里的读操作，也能保证在读取之后，才能对它进行写入！



在intelCPU层级上，也有系统原语的支持：sfence（save写屏障） mfence（m全屏障）

​																 lfence（load读屏障）



Hot Spot底层实现内存屏障的方式：lock指令，lock指令适用于x86架构的cpu，而fence原语是intelCPU指令集中才支持的。所以HS为了更广阔的兼容采用了lock指令的方案。

CPU层级：lock指令

一句话：直接把总线给锁了



x86机器上的"lock ..."指令是一个Full Barrier，执行是会锁住主内存子系统来确保执行顺序，甚至跨多个CPU。Software Locks通常使用了内存屏障或原子指令来实现变量可见性和保持程序顺序

和synchronized的 lock cmpxchg不同，volatile使用的原语是 lock acid，往esp寄存器上置一个空值，然后锁住内存总线



##### 场景：DCL（Double Check Lock）到底需不需要Volatile？

这里涉及到new一个对象时到底发生了什么？

检查过程字节码可知：创建过程起码有三个步骤

T t = new T();

```java
0 new #2 <T>  //类似于c++中的malloc，为对象初始化内存空间
4 invokespecial #3 <T.<init>> //调用对象的构造方法
7 restore_1 //为栈中的t变量建立指向堆空间中对象的引用
```

假设，实际执行过程中发生了指令重排，0 4 7 的执行顺序变成了 0 7 4**（这是结果一致的）**

那么在对象初始化之前，就会有t指向半初始化状态的引用

而在多线程状态下，这个引用的存在就使得其他线程可能实际用到半初始化状态的对象去执行后面的逻辑

带来线程的不安全

![image-20200723233813334](C:\Users\q1367\Desktop\jdk\DCL.png)

### Volatile并不能保证原子性

```java
public class JoinTest {
    volatile int count = 0;
    void m(){
        for (int i = 0; i<10000; i++){
//            System.out.println(Thread.currentThread().getName() + " count = " + count++);
            count++;
        }
    }

    public static void main(String[] args) {
        JoinTest t = new JoinTest();
        List<Thread> threads = new ArrayList<>(10);
        for (int i = 0; i < 10; i++){
            threads.add(new Thread(t::m,"thread - " +  i));
        }
        threads.forEach(thread -> {
            thread.start();
        });

        threads.forEach(thread -> {
            try {
                thread.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        System.out.println(t.count);
    }
}
```

解释：比如第一次count++，也正常写回了，但是同时可能有n个线程拿到此时count的值，分别+1再写回，就失去了n-1次相加

因为count++不是原子性的，起码分成取值、计算、存储三个步骤，可能接连着多个时间片许多线程都先执行了取值指令。



## 锁优化

### 细化与粗化

粗化：争用特别频繁（循环中访问锁

细化：没必要对整个方法进行上锁，只需要针对会用到共享数据的代码块加锁即可

